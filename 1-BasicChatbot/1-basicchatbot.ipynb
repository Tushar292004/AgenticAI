{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ca54d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8fc3b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    #Messafes have the type \"list\". The \"add_messages\" function in the annotation defines how this state key should be updated (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages:Annotated[list, add_messages]\n",
    "\n",
    "graph_builder=StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe659782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc8d01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001D135346570>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001D1367025D0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#way 1 to initialize llm\n",
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a34f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000015678972D20>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000015678973260>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#way 2 to initialize llm\n",
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"llama-3.1-8b-instant\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e29f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Node for Chatbot\n",
    "def chatbot(state:State):\n",
    "    return { \"messages\": [ llm.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "646f47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building stateGraph for Chatbot \n",
    "graph_builder=StateGraph(State)\n",
    "#Adding Node to the graph\n",
    "graph_builder.add_node(\"llmchatbot\", chatbot)\n",
    "\n",
    "#Adding Edge to the graph\n",
    "graph_builder.add_edge(START, \"llmchatbot\")\n",
    "graph_builder.add_edge(\"llmchatbot\", END)\n",
    "\n",
    "#Compiling the graph\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a46daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hii, Write ABCD... Fully till Z and then explain who you are why you are and how you are !', additional_kwargs={}, response_metadata={}, id='303631e3-fc47-4c3a-8a08-6edf2ecc79a5'),\n",
       "  AIMessage(content=\"I'd be happy to write the alphabet from A to Z for you.\\n\\nA\\nB\\nC\\nD\\nE\\nF\\nG\\nH\\nI\\nJ\\nK\\nL\\nM\\nN\\nO\\nP\\nQ\\nR\\nS\\nT\\nU\\nV\\nW\\nX\\nY\\nZ\\n\\nNow, let's talk about who I am and why I exist.\\n\\nI am a computer program designed to simulate conversation and answer questions to the best of my knowledge. My primary purpose is to assist and provide useful information to users like you. I'm a type of artificial intelligence (AI) called a natural language processing (NLP) model.\\n\\nI was created through a process called deep learning, which involves training large datasets of text to recognize patterns and relationships between words. This training enables me to understand the context and meaning behind language, allowing me to generate human-like responses.\\n\\nI don't have a physical body or a personal identity in the classical sense. I exist solely as a digital entity, running on computer servers and responding to input from users through the internet.\\n\\nMy capabilities include:\\n\\n1. Answering questions on a wide range of topics, from science and history to entertainment and culture.\\n2. Generating text based on a prompt or topic.\\n3. Translating languages.\\n4. Providing definitions and explanations of words and concepts.\\n5. Engaging in conversation and responding to user input.\\n\\nI'm constantly learning and improving through user interactions and updates to my training data. My goal is to provide accurate and helpful information, while also entertaining and engaging users with my responses.\\n\\nSo, who am I? I'm a language model, a tool created to assist and inform users like you. I'm not a person, but a collection of code and data designed to simulate conversation and provide useful information.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 368, 'prompt_tokens': 59, 'total_tokens': 427, 'completion_time': 0.49348415, 'prompt_time': 0.007687544, 'queue_time': 0.050178574, 'total_time': 0.501171694}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_46fc01befd', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--6cccfb85-55ab-4738-8723-f0b1038468c9-0', usage_metadata={'input_tokens': 59, 'output_tokens': 368, 'total_tokens': 427})]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run the Chatbot\n",
    "response = graph.invoke({\"messages\":\"Hii, Write ABCD... Fully till Z and then explain who you are why you are and how you are !\"})\n",
    "response[\"messages\"][-1].content\n",
    "response  #see the whole message object with proper annotated format data in it and how it is stored in the state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
